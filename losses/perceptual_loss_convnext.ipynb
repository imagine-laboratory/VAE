{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1bd98b",
   "metadata": {},
   "source": [
    "# Convnext Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b48caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from enum import Enum\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "\n",
    "class ConvNextType(Enum):\n",
    "    \"\"\"Available ConvNext model types\"\"\"\n",
    "    TINY = \"tiny\"\n",
    "    SMALL = \"small\"\n",
    "    BASE = \"base\"\n",
    "    LARGE = \"large\"\n",
    "\n",
    "def make_dummy_data(batch_size=1, channels=3, height=256, width=256, device='cuda'):\n",
    "    \"\"\"Create random tensor data for testing\"\"\"\n",
    "    return torch.randn(batch_size, channels, height, width, device=device)\n",
    "\n",
    "class ConvNextPerceptualLoss(nn.Module):\n",
    "    \"\"\"ConvNext Perceptual Loss Module\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        device: torch.device,\n",
    "        model_type: ConvNextType = ConvNextType.TINY,\n",
    "        feature_layers: List[int] = [0, 2, 4, 6, 8, 10, 12, 14],\n",
    "        feature_weights: Optional[List[float]] = None,\n",
    "        use_gram: bool = True,\n",
    "        input_range: Tuple[float, float] = (-1, 1),\n",
    "        layer_weight_decay: float = 1.0\n",
    "    ):\n",
    "        \"\"\"Initialize perceptual loss module\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.input_range = input_range\n",
    "        self.use_gram = use_gram\n",
    "        self.feature_layers = feature_layers\n",
    "        \n",
    "        # Calculate weights with decay if not specified\n",
    "        if feature_weights is None:\n",
    "            decay_values = [layer_weight_decay ** i for i in range(len(feature_layers))]\n",
    "            weights = torch.tensor(decay_values, device=device, dtype=torch.float32)\n",
    "            weights = weights / weights.sum()\n",
    "        else:\n",
    "            weights = torch.tensor(feature_weights, device=device, dtype=torch.float32)\n",
    "        \n",
    "        assert len(feature_layers) == len(weights), \"Number of feature layers must match number of weights\"\n",
    "        self.register_buffer(\"feature_weights\", weights)\n",
    "        \n",
    "        # Load pretrained ConvNext model\n",
    "        model_name = f\"convnext_{model_type.value}\"\n",
    "        try:\n",
    "            weights_enum = getattr(torchvision.models, f\"ConvNeXt_{model_type.value.capitalize()}_Weights\")\n",
    "            weights = weights_enum.DEFAULT\n",
    "            model = getattr(torchvision.models, model_name)(weights=weights)\n",
    "        except (AttributeError, ImportError):\n",
    "            model = getattr(torchvision.models, model_name)(pretrained=True)\n",
    "        \n",
    "        # Extract blocks and ensure they're in eval mode\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for stage in model.features:\n",
    "            if isinstance(stage, nn.Sequential):\n",
    "                self.blocks.extend(stage)\n",
    "            else:\n",
    "                self.blocks.append(stage)\n",
    "        \n",
    "        self.blocks = self.blocks.eval().to(device)\n",
    "        # Don't freeze parameters but set requires_grad=False since we don't update them\n",
    "        for param in self.blocks.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "        # Register normalization parameters\n",
    "        self.register_buffer(\n",
    "            \"mean\", \n",
    "            torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"std\", \n",
    "            torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def normalize_input(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Normalize input tensor\"\"\"\n",
    "        x = x.to(self.device)\n",
    "        \n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        # Ensure we create new leaf tensors while maintaining gradient flow\n",
    "        x = x - torch.tensor(0., device=self.device)  # Create new leaf tensor\n",
    "        \n",
    "        min_val, max_val = self.input_range\n",
    "        x = (x - min_val) / (max_val - min_val)\n",
    "        x = (x - self.mean) / self.std\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            x.retain_grad()  # Retain gradients for intermediate values\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def gram_matrix(self, x: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
    "        \"\"\"Compute Gram matrix of feature maps\"\"\"\n",
    "        b, c, h, w = x.size()\n",
    "        features = x.view(b, c, -1)\n",
    "        gram = torch.bmm(features, features.transpose(1, 2))\n",
    "        if normalize:\n",
    "            gram = gram / (c * h * w)\n",
    "        return gram\n",
    "    \n",
    "    def compute_feature_loss(\n",
    "        self, \n",
    "        input_features: List[torch.Tensor],\n",
    "        target_features: List[torch.Tensor],\n",
    "        layers_indices: List[int],\n",
    "        weights: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute feature loss ensuring scalar output\"\"\"\n",
    "        losses = []\n",
    "        \n",
    "        for idx, weight in zip(layers_indices, weights):\n",
    "            input_feat = input_features[idx]\n",
    "            target_feat = target_features[idx].detach()  # Detach target features\n",
    "            \n",
    "            if self.use_gram:\n",
    "                input_gram = self.gram_matrix(input_feat)\n",
    "                target_gram = self.gram_matrix(target_feat)\n",
    "                layer_loss = nn.functional.l1_loss(input_gram, target_gram)\n",
    "            else:\n",
    "                layer_loss = nn.functional.mse_loss(input_feat, target_feat, reduction=\"sum\")\n",
    "            \n",
    "            losses.append(weight * layer_loss)\n",
    "            \n",
    "        # Sum all losses and ensure scalar output\n",
    "        return torch.stack(losses).sum()\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward pass to compute loss\"\"\"\n",
    "        input = input.to(self.device)\n",
    "        target = target.to(self.device)\n",
    "        \n",
    "        input = self.normalize_input(input)\n",
    "        target = self.normalize_input(target)\n",
    "        \n",
    "        # Extract features\n",
    "        input_features = []\n",
    "        target_features = []\n",
    "        \n",
    "        x_input = input\n",
    "        x_target = target\n",
    "        for block in self.blocks:\n",
    "            x_input = block(x_input)\n",
    "            with torch.no_grad():  # No need to compute gradients for target features\n",
    "                x_target = block(x_target)\n",
    "            input_features.append(x_input)\n",
    "            target_features.append(x_target)\n",
    "        \n",
    "        loss = self.compute_feature_loss(\n",
    "            input_features, target_features,\n",
    "            self.feature_layers, self.feature_weights\n",
    "        )\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e25da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptual Loss (ConvNeXt): tensor(15595.8252, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Make sure you have a CUDA device if using 'cuda'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create dummy input and target images\n",
    "input_tensor = make_dummy_data(batch_size=1, channels=3, height=256, width=256, device=device)\n",
    "target_tensor = make_dummy_data(batch_size=1, channels=3, height=256, width=256, device=device)\n",
    "\n",
    "# Instantiate the perceptual loss module using ConvNeXt-Tiny\n",
    "loss_fn = ConvNextPerceptualLoss(\n",
    "    device=device,\n",
    "    model_type=ConvNextType.TINY,\n",
    "    feature_layers=[1, 3, 5],  # Use fewer layers for speed in this dummy test\n",
    "    use_gram=False,            # Use direct feature comparison instead of Gram matrix\n",
    "    layer_weight_decay=0.8     # Weight decay across layers\n",
    ")\n",
    "\n",
    "# Compute the perceptual loss between input and target\n",
    "loss_value = loss_fn(input_tensor, target_tensor)\n",
    "\n",
    "# Print the computed loss\n",
    "print(\"Perceptual Loss (ConvNeXt):\", loss_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
